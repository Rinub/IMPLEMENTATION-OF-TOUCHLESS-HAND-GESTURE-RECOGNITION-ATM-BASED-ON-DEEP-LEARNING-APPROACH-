{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Hand_Gesture_Recognition_ATM.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9wJaufBvfUi",
        "outputId": "6fda897b-d55d-4260-a371-fe14c7a1c41a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "sOEWF3zAvRVt"
      },
      "source": [
        "import io\n",
        "import openpyxl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUhJeEdRvRVv"
      },
      "source": [
        "# 3. Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO__MTWxvRVv",
        "outputId": "658040a0-4eae-40f0-e9e2-ece8368382d5"
      },
      "source": [
        "\n",
        "\n",
        "ds_asl_dir = \"/content/drive/MyDrive/asl_dataset\"\n",
        "\n",
        "#Generating a dataset\n",
        "\n",
        "asl_ds = tf.keras.preprocessing.image_dataset_from_directory(ds_asl_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 910 files belonging to 13 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUc6hpAMvRVv"
      },
      "source": [
        "# 4. Data Preliminary Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "AS8SIHjpvRVw",
        "outputId": "da1992db-623b-4dba-d134-1e08deeaefb1"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"none\"\n",
        "\n",
        "\n",
        "!ls \"/content/drive/MyDrive/asl_dataset\"\n",
        "\n",
        "#Showing index + class\n",
        "\n",
        "pd.DataFrame(asl_ds.class_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  2  4  6  8  Check_Account_Balance  Withdraw_Cash\n",
            "1  3  5  7  9  Deposit_cash\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Check_Account_Balance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Deposit_cash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Withdraw_Cash</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        0\n",
              "0                       0\n",
              "1                       1\n",
              "2                       2\n",
              "3                       3\n",
              "4                       4\n",
              "5                       5\n",
              "6                       6\n",
              "7                       7\n",
              "8                       8\n",
              "9                       9\n",
              "10  Check_Account_Balance\n",
              "11           Deposit_cash\n",
              "12          Withdraw_Cash"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4_y783SvRVx",
        "outputId": "e6e01897-565a-4715-df83-fdd2597245d5"
      },
      "source": [
        "\n",
        "\n",
        "for image_batch, labels_batch in asl_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 256, 256, 3)\n",
            "(32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tmYbYQsAvRVy"
      },
      "source": [
        "#Displaying some pictureÂ´s size\n",
        "\n",
        "from PIL import Image\n",
        "img =  Image.open(\"/kaggle/working/asl_dataset/asl_dataset/0/hand1_0_bot_seg_1_cropped.jpeg\")\n",
        "width, height = img.size\n",
        "print(f\"Image sample with width={width} and height={height}.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GmRI8T0NvRVz"
      },
      "source": [
        "#Displaying image samples\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in asl_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(int(labels[i]))\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucOdbfREvRV0"
      },
      "source": [
        "# 5. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YvsZHXsOvRV0"
      },
      "source": [
        "#Defining parameters for the loader\n",
        "\n",
        "batch_size = 32\n",
        "img_height = 64\n",
        "img_width = 64\n",
        "\n",
        "#Filtering out corrupted images\n",
        "\n",
        "import os\n",
        "num_skipped = 0\n",
        "for folder_name in (\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\"\n",
        "                    ,\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"):\n",
        "    folder_path = os.path.join(ds_asl_dir, folder_name)\n",
        "    for fname in os.listdir(folder_path):\n",
        "        fpath = os.path.join(folder_path, fname)\n",
        "        try:\n",
        "            fobj = open(fpath, \"rb\")\n",
        "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
        "        finally:\n",
        "            fobj.close()\n",
        "        if not is_jfif:\n",
        "            num_skipped += 1\n",
        "            # Delete corrupted image\n",
        "            os.remove(fpath)\n",
        "print(\"Deleted %d images\" % num_skipped)\n",
        "\n",
        "#Augmenting the images\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "data_augmentation = ImageDataGenerator(rotation_range=15, rescale=1/255, zoom_range=0.1, horizontal_flip=True,\n",
        "                                       width_shift_range=0.1, height_shift_range=0.1, validation_split=0.2)\n",
        "\n",
        "#Setting train/test split\n",
        "\n",
        "asl_train_ds = data_augmentation.flow_from_directory(directory=ds_asl_dir, target_size=(img_height, img_width),\n",
        "                                                     class_mode=\"categorical\", batch_size=batch_size, subset=\"training\")\n",
        "asl_test_ds = data_augmentation.flow_from_directory(directory=ds_asl_dir, target_size=(img_height, img_width),\n",
        "                                                    class_mode=\"categorical\", batch_size=batch_size, subset=\"validation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1dbGdB4vRV1"
      },
      "source": [
        "# 6. Data Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0-gn5_qjvRV1"
      },
      "source": [
        "from keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense\n",
        "\n",
        "#Checking if the data format i.e the RGB channel is coming first or last so, whatever it may be, model will check first and then input shape will be feeded accordingly.\n",
        "\n",
        "from keras import backend as K\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    input_shape = (3, img_height, img_width)\n",
        "else:\n",
        "    input_shape = (img_height, img_width, 3)\n",
        "\n",
        "#Creating a model\n",
        "\n",
        "model_dl = keras.Sequential()\n",
        "model_dl.add(Conv2D(16,(3,3),activation=\"relu\",input_shape=(input_shape)))\n",
        "model_dl.add(MaxPool2D(2,2))\n",
        "model_dl.add(Dropout(0.2))\n",
        "model_dl.add(Conv2D(32,(3,3),activation=\"relu\"))\n",
        "model_dl.add(MaxPool2D(2,2))\n",
        "model_dl.add(Dropout(0.2))\n",
        "model_dl.add(Conv2D(64,(3,3),activation=\"relu\"))\n",
        "model_dl.add(MaxPool2D(2,2))\n",
        "model_dl.add(Dropout(0.2))\n",
        "model_dl.add(Flatten())\n",
        "model_dl.add(Dense(128,activation=\"relu\"))\n",
        "model_dl.add(Dropout(0.2))\n",
        "model_dl.add(Dense(36,activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H9LY7pXvRV2"
      },
      "source": [
        "# 7. Deep Learning Algorithm Implementation & Assessment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "557YTGWRvRV2"
      },
      "source": [
        "#Compiling the neural network\n",
        "\n",
        "model_dl.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "#Fitting to the model\n",
        "\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau #Import callback functions\n",
        "earlystop=EarlyStopping(patience=10) #Monitor the performance. If it dips, then stop training\n",
        "learning_rate_reduce=ReduceLROnPlateau(monitor=\"val_acc\",min_lr=0.001) #Change learning rate if not performing good enough\n",
        "callbacks=[earlystop,learning_rate_reduce]\n",
        "\n",
        "model_dl.fit(asl_train_ds, validation_data=asl_test_ds, callbacks=callbacks, epochs=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZI1Wer5CvRV3"
      },
      "source": [
        "#Saving the model\n",
        "\n",
        "model_dl.save(\"model_dl.h5\")\n",
        "\n",
        "#Loading themodel\n",
        "\n",
        "model_dl = keras.models.load_model(\"model_dl.h5\") #look for local saved file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttSHmpFqvRV3"
      },
      "source": [
        "# 8. Model Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pU6kQPDzvRV3"
      },
      "source": [
        "#WeÂ´ll use any image sample from the Kaggle dataset to test it \n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#Creating a dictionary to map each of the indexes to the corresponding number or letter\n",
        "\n",
        "dict = {0:\"0\",1:\"1\",2:\"2\",3:\"3\",4:\"4\",5:\"5\",6:\"6\",7:\"7\",8:\"8\",9:\"9\",10:\"a\",11:\"b\",12:\"c\",13:\"d\",14:\"e\",15:\"f\",16:\"g\",\n",
        "        17:\"h\",18:\"i\",19:\"j\",20:\"k\",21:\"l\",22:\"m\",23:\"n\",24:\"o\",25:\"p\",26:\"q\",27:\"r\",28:\"s\",29:\"t\",30:\"u\",31:\"v\",32:\"w\",\n",
        "        33:\"x\",34:\"y\",35:\"z\"}\n",
        "\n",
        "#Predicting images\n",
        "\n",
        "img = image.load_img(\"/kaggle/working/asl_dataset/asl_dataset/a/hand1_a_bot_seg_1_cropped.jpeg\", target_size=(img_width, img_height))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "image = np.vstack([x])\n",
        "classes = model_dl.predict_classes(image, batch_size=batch_size)\n",
        "probabilities = model_dl.predict_proba(image, batch_size=batch_size)\n",
        "probabilities_formatted = list(map(\"{:.2f}%\".format, probabilities[0]*100))\n",
        "\n",
        "print(classes) #displaying matrix prediction position\n",
        "\n",
        "print(f'The predicted image corresponds to \"{dict[classes.item()]}\" with {probabilities_formatted[classes.item()]} probability.') #displaying matrix prediction position name (number or letter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1Ll61ZIvRV4"
      },
      "source": [
        "# 9. Conclusions\n",
        "\n",
        "IF YOU LIKE IT OR IF IT HELPS YOU SOMEHOW, COULD YOU PLEASE UPVOTE? THANK YOU VERY MUCH!!!\n",
        "\n",
        "We were able to develop a neural netork model with 83% accuracy when identifying pictures of the American Sign Language, what hopefully could be further developed to help on communication for the hearing impaired communities."
      ]
    }
  ]
}